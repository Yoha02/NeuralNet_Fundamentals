{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Neural Network Fundamentals\n",
        "\n",
        "## Part 5: Training - Learning from Mistakes\n",
        "\n",
        "### The Brain's Decision Committee - Chapter 5\n",
        "\n",
        "---\n",
        "\n",
        "## The Story So Far...\n",
        "\n",
        "In Part 4, our committee member attempted their first classification task. They looked at images of vertical and horizontal lines and tried to identify them. The results were... not great. With random weights, they achieved about 50% accuracy - no better than flipping a coin.\n",
        "\n",
        "**But here's the beautiful thing about neural networks: they can learn from their mistakes.**\n",
        "\n",
        "In this notebook, we'll teach our Perceptron how to improve. We'll show it examples, tell it when it's wrong, and let it gradually adjust its weights until it becomes an expert line detector.\n",
        "\n",
        "This is **training** - the heart of machine learning.\n",
        "\n",
        "---\n",
        "\n",
        "## What You'll Learn in Part 5\n",
        "\n",
        "This is one of the most important notebooks in the series. By the end, you will understand:\n",
        "\n",
        "1. **Loss Functions** - How to measure \"how wrong\" a prediction is\n",
        "2. **Why We Square Errors** - The mathematical reason behind MSE\n",
        "3. **Binary Cross-Entropy** - The preferred loss for classification (and why!)\n",
        "4. **Gradient Descent** - The algorithm that finds better weights\n",
        "5. **Learning Rate** - How fast to adjust (and what happens if it's wrong)\n",
        "6. **The Gradient** - The direction of steepest improvement\n",
        "7. **Backpropagation** - How errors flow backward through the network\n",
        "8. **The Training Loop** - Putting it all together\n",
        "9. **Watch It Learn** - See the Perceptron go from 50% to 95%+ accuracy!\n",
        "\n",
        "---\n",
        "\n",
        "## Prerequisites\n",
        "\n",
        "Make sure you've completed:\n",
        "- **Parts 0-1:** Matrices (`neural_network_fundamentals.ipynb`)\n",
        "- **Part 2:** Single Neuron (`part_2_single_neuron.ipynb`)\n",
        "- **Part 3:** Activation Functions (`part_3_activation_functions.ipynb`)\n",
        "- **Part 4:** The Perceptron (`part_4_perceptron.ipynb`)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## Setup: Import Dependencies and Recreate Our Tools\n",
        "\n",
        "Let's bring in everything we built in previous notebooks.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# =============================================================================\n",
        "# PART 5: TRAINING - SETUP AND IMPORTS\n",
        "# =============================================================================\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython.display import display, clear_output\n",
        "\n",
        "# Try to import ipywidgets for interactive features\n",
        "try:\n",
        "    import ipywidgets as widgets\n",
        "    WIDGETS_AVAILABLE = True\n",
        "except ImportError:\n",
        "    WIDGETS_AVAILABLE = False\n",
        "    print(\"Note: ipywidgets not installed. Interactive features will be limited.\")\n",
        "\n",
        "# Set up matplotlib style\n",
        "style_options = ['seaborn-v0_8-whitegrid', 'seaborn-whitegrid', 'ggplot', 'default']\n",
        "for style in style_options:\n",
        "    try:\n",
        "        plt.style.use(style)\n",
        "        break\n",
        "    except OSError:\n",
        "        continue\n",
        "\n",
        "plt.rcParams['figure.figsize'] = [10, 6]\n",
        "plt.rcParams['font.size'] = 12\n",
        "np.random.seed(42)\n",
        "\n",
        "print(\"Setup complete!\")\n",
        "print(\"=\"*60)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# =============================================================================\n",
        "# RECREATE OUR TOOLS FROM PREVIOUS NOTEBOOKS\n",
        "# =============================================================================\n",
        "\n",
        "# -----------------------------------------------------------------------------\n",
        "# Our canonical line images (from Part 1)\n",
        "# -----------------------------------------------------------------------------\n",
        "vertical_line = np.array([[0, 1, 0], [0, 1, 0], [0, 1, 0]])\n",
        "horizontal_line = np.array([[0, 0, 0], [1, 1, 1], [0, 0, 0]])\n",
        "vertical_flat = vertical_line.flatten()\n",
        "horizontal_flat = horizontal_line.flatten()\n",
        "\n",
        "# -----------------------------------------------------------------------------\n",
        "# Dataset generator (from Part 4)\n",
        "# -----------------------------------------------------------------------------\n",
        "def generate_line_dataset(n_samples=100, noise_level=0.0, seed=None):\n",
        "    \"\"\"Generate vertical (label=1) and horizontal (label=0) line images.\"\"\"\n",
        "    if seed is not None:\n",
        "        np.random.seed(seed)\n",
        "    \n",
        "    X, y = [], []\n",
        "    \n",
        "    for i in range(n_samples):\n",
        "        image = np.zeros((3, 3))\n",
        "        \n",
        "        if i < n_samples // 2:  # Vertical lines\n",
        "            col = np.random.randint(0, 3)\n",
        "            image[:, col] = 1\n",
        "            if noise_level > 0:\n",
        "                image = np.clip(image + np.random.randn(3, 3) * noise_level, 0, 1)\n",
        "            X.append(image.flatten())\n",
        "            y.append(1)\n",
        "        else:  # Horizontal lines\n",
        "            row = np.random.randint(0, 3)\n",
        "            image[row, :] = 1\n",
        "            if noise_level > 0:\n",
        "                image = np.clip(image + np.random.randn(3, 3) * noise_level, 0, 1)\n",
        "            X.append(image.flatten())\n",
        "            y.append(0)\n",
        "    \n",
        "    X, y = np.array(X), np.array(y)\n",
        "    shuffle_idx = np.random.permutation(n_samples)\n",
        "    return X[shuffle_idx], y[shuffle_idx]\n",
        "\n",
        "# -----------------------------------------------------------------------------\n",
        "# Sigmoid activation function (from Part 3)\n",
        "# -----------------------------------------------------------------------------\n",
        "def sigmoid(z):\n",
        "    \"\"\"Sigmoid activation: maps any value to range (0, 1).\"\"\"\n",
        "    return 1 / (1 + np.exp(-np.clip(z, -500, 500)))\n",
        "\n",
        "# -----------------------------------------------------------------------------\n",
        "# Basic Perceptron class (from Part 4) - We'll add training later!\n",
        "# -----------------------------------------------------------------------------\n",
        "class Perceptron:\n",
        "    \"\"\"A single-layer Perceptron for binary classification.\"\"\"\n",
        "    \n",
        "    def __init__(self, n_inputs):\n",
        "        self.weights = np.random.randn(n_inputs) * 0.1\n",
        "        self.bias = 0.0\n",
        "        self.n_inputs = n_inputs\n",
        "    \n",
        "    def forward(self, x):\n",
        "        \"\"\"Compute the forward pass.\"\"\"\n",
        "        x = np.array(x).flatten()\n",
        "        z = np.dot(self.weights, x) + self.bias\n",
        "        return sigmoid(z)\n",
        "    \n",
        "    def predict(self, x):\n",
        "        \"\"\"Make a binary prediction (0 or 1).\"\"\"\n",
        "        return 1 if self.forward(x) >= 0.5 else 0\n",
        "\n",
        "# Generate our training dataset\n",
        "X_train, y_train = generate_line_dataset(n_samples=100, noise_level=0.0, seed=42)\n",
        "\n",
        "print(\"Tools recreated from previous notebooks!\")\n",
        "print(f\"  - Vertical/Horizontal line templates\")\n",
        "print(f\"  - Dataset generator\")\n",
        "print(f\"  - Sigmoid activation\")\n",
        "print(f\"  - Basic Perceptron class\")\n",
        "print(f\"\\nTraining dataset: {len(X_train)} samples\")\n",
        "print(f\"  - {sum(y_train)} vertical lines (label=1)\")\n",
        "print(f\"  - {len(y_train) - sum(y_train)} horizontal lines (label=0)\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## 5.1 The Error: How Wrong Are We?\n",
        "\n",
        "Before we can improve, we need to measure **how wrong** our predictions are. This is the foundation of learning.\n",
        "\n",
        "### The Basic Idea\n",
        "\n",
        "When our Perceptron makes a prediction, we compare it to the actual answer:\n",
        "\n",
        "```\n",
        "Error = Actual Value - Predicted Value\n",
        "      = y - ŷ\n",
        "```\n",
        "\n",
        "### A Concrete Example\n",
        "\n",
        "Let's say we show the Perceptron a **vertical line** (actual label y = 1):\n",
        "\n",
        "| Scenario | Prediction (ŷ) | Error (y - ŷ) | Interpretation |\n",
        "|----------|----------------|---------------|----------------|\n",
        "| Perfect | 1.0 | 1.0 - 1.0 = 0.0 | No error! |\n",
        "| Good | 0.9 | 1.0 - 0.9 = 0.1 | Small error |\n",
        "| Bad | 0.3 | 1.0 - 0.3 = 0.7 | Big error! |\n",
        "| Terrible | 0.0 | 1.0 - 0.0 = 1.0 | Maximum error |\n",
        "\n",
        "### Committee Analogy\n",
        "\n",
        "*\"The committee member votes on a case. After the vote, the supervisor reveals the correct answer. The difference between their vote and the correct answer is their ERROR - and they need to learn from it.\"*\n",
        "\n",
        "### Why Error Matters\n",
        "\n",
        "The error tells us two things:\n",
        "1. **How much** to adjust (larger error = bigger adjustment needed)\n",
        "2. **Which direction** to adjust (positive error = increase output, negative = decrease)\n",
        "\n",
        "Let's see this with real numbers:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# =============================================================================\n",
        "# CALCULATING ERROR: Step by Step\n",
        "# =============================================================================\n",
        "\n",
        "# Create an untrained Perceptron\n",
        "perceptron = Perceptron(n_inputs=9)\n",
        "\n",
        "print(\"=\"*70)\n",
        "print(\"CALCULATING ERROR: Step by Step\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# Test on a vertical line (actual label = 1)\n",
        "print(\"\\n\" + \"-\"*70)\n",
        "print(\"Example 1: Testing on a VERTICAL line\")\n",
        "print(\"-\"*70)\n",
        "\n",
        "y_actual = 1  # The true label (it IS a vertical line)\n",
        "y_predicted = perceptron.forward(vertical_flat)\n",
        "\n",
        "print(f\"\\n  Step 1: Get the actual label\")\n",
        "print(f\"          y (actual) = {y_actual}\")\n",
        "print(f\"          This means: 'This IS a vertical line'\")\n",
        "\n",
        "print(f\"\\n  Step 2: Get the prediction from our Perceptron\")\n",
        "print(f\"          ŷ (predicted) = {y_predicted:.4f}\")\n",
        "print(f\"          This means: '{y_predicted*100:.1f}% confident it's vertical'\")\n",
        "\n",
        "print(f\"\\n  Step 3: Calculate the error\")\n",
        "print(f\"          error = y - ŷ\")\n",
        "print(f\"          error = {y_actual} - {y_predicted:.4f}\")\n",
        "error_vertical = y_actual - y_predicted\n",
        "print(f\"          error = {error_vertical:.4f}\")\n",
        "\n",
        "print(f\"\\n  Interpretation:\")\n",
        "if error_vertical > 0:\n",
        "    print(f\"          The error is POSITIVE ({error_vertical:.4f})\")\n",
        "    print(f\"          This means: The Perceptron underestimated! It should output HIGHER.\")\n",
        "else:\n",
        "    print(f\"          The error is NEGATIVE ({error_vertical:.4f})\")\n",
        "    print(f\"          This means: The Perceptron overestimated! It should output LOWER.\")\n",
        "\n",
        "# Test on a horizontal line (actual label = 0)\n",
        "print(\"\\n\" + \"-\"*70)\n",
        "print(\"Example 2: Testing on a HORIZONTAL line\")\n",
        "print(\"-\"*70)\n",
        "\n",
        "y_actual_h = 0  # The true label (it is NOT a vertical line)\n",
        "y_predicted_h = perceptron.forward(horizontal_flat)\n",
        "\n",
        "print(f\"\\n  Step 1: Get the actual label\")\n",
        "print(f\"          y (actual) = {y_actual_h}\")\n",
        "print(f\"          This means: 'This is NOT a vertical line'\")\n",
        "\n",
        "print(f\"\\n  Step 2: Get the prediction from our Perceptron\")\n",
        "print(f\"          ŷ (predicted) = {y_predicted_h:.4f}\")\n",
        "print(f\"          This means: '{y_predicted_h*100:.1f}% confident it's vertical'\")\n",
        "\n",
        "print(f\"\\n  Step 3: Calculate the error\")\n",
        "print(f\"          error = y - ŷ\")\n",
        "print(f\"          error = {y_actual_h} - {y_predicted_h:.4f}\")\n",
        "error_horizontal = y_actual_h - y_predicted_h\n",
        "print(f\"          error = {error_horizontal:.4f}\")\n",
        "\n",
        "print(f\"\\n  Interpretation:\")\n",
        "if error_horizontal > 0:\n",
        "    print(f\"          The error is POSITIVE ({error_horizontal:.4f})\")\n",
        "    print(f\"          This means: The Perceptron underestimated!\")\n",
        "elif error_horizontal < 0:\n",
        "    print(f\"          The error is NEGATIVE ({error_horizontal:.4f})\")\n",
        "    print(f\"          This means: The Perceptron overestimated! It should output LOWER.\")\n",
        "else:\n",
        "    print(f\"          The error is ZERO - perfect prediction!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## 5.2 Loss Functions: The Teacher's Grading System\n",
        "\n",
        "Before we look at specific formulas, let's understand **what a loss function is and why we need one**.\n",
        "\n",
        "### What is a Loss Function?\n",
        "\n",
        "A **loss function** (also called a \"cost function\" or \"objective function\") is a mathematical formula that:\n",
        "- Takes in predictions and actual labels\n",
        "- Outputs a **single number** representing \"how wrong\" the predictions are\n",
        "- **Lower is better** - a loss of 0 means perfect predictions\n",
        "\n",
        "### Why Do We Need Loss Functions?\n",
        "\n",
        "Think about learning anything - you need **feedback** to improve. The loss function provides that feedback:\n",
        "\n",
        "| Without Loss Function | With Loss Function |\n",
        "|----------------------|-------------------|\n",
        "| \"Your predictions are wrong\" | \"Your predictions are 0.25 wrong\" |\n",
        "| Vague, not actionable | Precise, quantifiable |\n",
        "| Can't compare methods | Can compare: 0.25 vs 0.15 |\n",
        "| Can't track progress | Can see improvement over time |\n",
        "\n",
        "### The Role of Loss in Training\n",
        "\n",
        "Loss functions are the **heart of machine learning**. The entire training process is:\n",
        "1. Make predictions\n",
        "2. **Calculate loss** (how wrong?)\n",
        "3. Adjust weights to **reduce loss**\n",
        "4. Repeat\n",
        "\n",
        "**The weights that minimize loss are the \"best\" weights** - that's the entire goal of training!\n",
        "\n",
        "### Committee Analogy\n",
        "\n",
        "*\"The loss function is like a performance review score. Every time the committee member makes a decision, they get a score. A perfect decision scores 0. A terrible decision scores high. The member's goal is to adjust their behavior to minimize this score over time.\"*\n",
        "\n",
        "---\n",
        "\n",
        "## 5.2.1 Mean Squared Error (MSE): Our First Loss Function\n",
        "\n",
        "Now let's look at a specific loss function: **Mean Squared Error** (MSE).\n",
        "\n",
        "Simple error (y - ŷ) has a problem: positive and negative errors can cancel out!\n",
        "\n",
        "**Example:** If we have two predictions:\n",
        "- Prediction 1: error = +0.5 (underestimated)\n",
        "- Prediction 2: error = -0.5 (overestimated)\n",
        "- Average error = (+0.5 + -0.5) / 2 = 0 ← Looks perfect, but it's NOT!\n",
        "\n",
        "### The Solution: Square the Errors\n",
        "\n",
        "By squaring each error before averaging, we solve this problem:\n",
        "\n",
        "$$\\text{MSE} = \\frac{1}{n} \\sum_{i=1}^{n} (y_i - \\hat{y}_i)^2$$\n",
        "\n",
        "Let's break this formula down piece by piece:\n",
        "\n",
        "| Symbol | Meaning | Example |\n",
        "|--------|---------|---------|\n",
        "| $n$ | Number of samples | 100 images |\n",
        "| $y_i$ | Actual label for sample $i$ | 1 (vertical) |\n",
        "| $\\hat{y}_i$ | Predicted value for sample $i$ | 0.7 |\n",
        "| $(y_i - \\hat{y}_i)$ | Error for sample $i$ | 1 - 0.7 = 0.3 |\n",
        "| $(y_i - \\hat{y}_i)^2$ | Squared error | 0.3² = 0.09 |\n",
        "| $\\frac{1}{n}\\sum$ | Average of all squared errors | Mean |\n",
        "\n",
        "### Why Square?\n",
        "\n",
        "Squaring the errors has three important benefits:\n",
        "\n",
        "1. **No Cancellation:** Positive and negative errors both become positive\n",
        "2. **Penalize Big Errors:** A small error (0.1) becomes tiny (0.01), but a big error (0.9) becomes large (0.81)\n",
        "3. **Smooth Landscape:** Creates a smooth \"bowl\" shape that's easy to optimize (more on this later)\n",
        "\n",
        "### Let's Calculate MSE Step by Step:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# =============================================================================\n",
        "# MEAN SQUARED ERROR: Step by Step Calculation\n",
        "# =============================================================================\n",
        "\n",
        "print(\"=\"*70)\n",
        "print(\"MEAN SQUARED ERROR (MSE): Step by Step\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# Let's use 5 samples to make this clear\n",
        "sample_actuals = np.array([1, 1, 0, 0, 1])       # True labels\n",
        "sample_predictions = np.array([0.9, 0.6, 0.3, 0.1, 0.5])  # Our predictions\n",
        "\n",
        "print(\"\\nOur data:\")\n",
        "print(f\"  Actual labels (y):      {sample_actuals}\")\n",
        "print(f\"  Predictions (ŷ):        {sample_predictions}\")\n",
        "\n",
        "# Step 1: Calculate each error\n",
        "print(\"\\n\" + \"-\"*70)\n",
        "print(\"STEP 1: Calculate each error (y - ŷ)\")\n",
        "print(\"-\"*70)\n",
        "errors = sample_actuals - sample_predictions\n",
        "print(f\"\\n  Sample 1: {sample_actuals[0]} - {sample_predictions[0]} = {errors[0]:.2f}\")\n",
        "print(f\"  Sample 2: {sample_actuals[1]} - {sample_predictions[1]} = {errors[1]:.2f}\")\n",
        "print(f\"  Sample 3: {sample_actuals[2]} - {sample_predictions[2]} = {errors[2]:.2f}\")\n",
        "print(f\"  Sample 4: {sample_actuals[3]} - {sample_predictions[3]} = {errors[3]:.2f}\")\n",
        "print(f\"  Sample 5: {sample_actuals[4]} - {sample_predictions[4]} = {errors[4]:.2f}\")\n",
        "print(f\"\\n  All errors: {errors}\")\n",
        "\n",
        "# Step 2: Square each error\n",
        "print(\"\\n\" + \"-\"*70)\n",
        "print(\"STEP 2: Square each error (to make all positive)\")\n",
        "print(\"-\"*70)\n",
        "squared_errors = errors ** 2\n",
        "print(f\"\\n  Sample 1: ({errors[0]:.2f})² = {squared_errors[0]:.4f}\")\n",
        "print(f\"  Sample 2: ({errors[1]:.2f})² = {squared_errors[1]:.4f}\")\n",
        "print(f\"  Sample 3: ({errors[2]:.2f})² = {squared_errors[2]:.4f}\")\n",
        "print(f\"  Sample 4: ({errors[3]:.2f})² = {squared_errors[3]:.4f}\")\n",
        "print(f\"  Sample 5: ({errors[4]:.2f})² = {squared_errors[4]:.4f}\")\n",
        "print(f\"\\n  Squared errors: {squared_errors}\")\n",
        "\n",
        "# Step 3: Take the mean\n",
        "print(\"\\n\" + \"-\"*70)\n",
        "print(\"STEP 3: Take the mean (average)\")\n",
        "print(\"-\"*70)\n",
        "mse = np.mean(squared_errors)\n",
        "print(f\"\\n  Sum of squared errors: {np.sum(squared_errors):.4f}\")\n",
        "print(f\"  Number of samples: {len(squared_errors)}\")\n",
        "print(f\"  MSE = Sum / n = {np.sum(squared_errors):.4f} / {len(squared_errors)}\")\n",
        "print(f\"  MSE = {mse:.4f}\")\n",
        "\n",
        "# The MSE function\n",
        "print(\"\\n\" + \"-\"*70)\n",
        "print(\"THE MSE FUNCTION (for reuse)\")\n",
        "print(\"-\"*70)\n",
        "\n",
        "def mse_loss(y_true, y_pred):\n",
        "    \"\"\"\n",
        "    Mean Squared Error loss function.\n",
        "    \n",
        "    Formula: MSE = (1/n) * Σ(y - ŷ)²\n",
        "    \n",
        "    Parameters:\n",
        "        y_true: Array of actual labels (0 or 1)\n",
        "        y_pred: Array of predicted probabilities (0 to 1)\n",
        "    \n",
        "    Returns:\n",
        "        Single value representing average squared error\n",
        "    \"\"\"\n",
        "    return np.mean((y_true - y_pred) ** 2)\n",
        "\n",
        "# Verify our calculation\n",
        "print(f\"\\n  Using our function: mse_loss(y, ŷ) = {mse_loss(sample_actuals, sample_predictions):.4f}\")\n",
        "print(f\"  Our manual calculation: {mse:.4f}\")\n",
        "print(f\"  Match: {'Yes!' if abs(mse_loss(sample_actuals, sample_predictions) - mse) < 0.0001 else 'No'}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## 5.3 Binary Cross-Entropy: The Better Loss for Classification\n",
        "\n",
        "MSE works, but for **classification** problems (like our V/H detection), there's a better loss function: **Binary Cross-Entropy** (BCE).\n",
        "\n",
        "### First, Let's Understand the Name\n",
        "\n",
        "The name \"Binary Cross-Entropy\" has three parts:\n",
        "\n",
        "| Term | Meaning | Our Context |\n",
        "|------|---------|-------------|\n",
        "| **Binary** | Two classes only | Vertical (1) or Horizontal (0) |\n",
        "| **Cross** | Comparing two distributions | Comparing predictions vs reality |\n",
        "| **Entropy** | Measure of uncertainty/surprise | How \"surprised\" we are by the outcome |\n",
        "\n",
        "**Entropy** comes from information theory. It measures uncertainty:\n",
        "- If something is certain (100% probability), entropy is 0 - no surprise!\n",
        "- If something is uncertain (50/50), entropy is high - maximum surprise!\n",
        "\n",
        "**Cross-entropy** compares what we PREDICTED against what ACTUALLY happened.\n",
        "\n",
        "### Why Not Just Use MSE?\n",
        "\n",
        "MSE works for regression (predicting continuous values like house prices), but classification has a special property: **we're predicting probabilities**.\n",
        "\n",
        "**The Problem with MSE:** When the prediction is very wrong (e.g., predicting 0.01 for a true label of 1), MSE gives an error of 0.99² = 0.98. That's bad, but is it bad *enough*?\n",
        "\n",
        "Consider: predicting 0.01 when you should predict 1.0 means you were **99% confident and COMPLETELY wrong**. That deserves a HUGE penalty!\n",
        "\n",
        "**BCE's Solution:** BCE uses logarithms, which give **much harsher penalties** for confident wrong answers.\n",
        "\n",
        "### The Logarithm: Why It's Perfect for This\n",
        "\n",
        "The **logarithm** is a special mathematical function. Here's why it works for measuring surprise:\n",
        "\n",
        "- `log(1) = 0` → If probability was 100%, no surprise at all\n",
        "- `log(0.5) ≈ -0.69` → Uncertain, some surprise\n",
        "- `log(0.1) ≈ -2.30` → Low probability, big surprise!\n",
        "- `log(0.01) ≈ -4.61` → Very low probability, huge surprise!\n",
        "- `log(0) = -∞` → Zero probability, infinite surprise (impossible event!)\n",
        "\n",
        "The negative sign flips these to positive loss values: `-log(0.01) = 4.61`\n",
        "\n",
        "### The Intuition: Measuring \"Surprise\"\n",
        "\n",
        "Think of cross-entropy as measuring **how surprised** you are by the actual answer:\n",
        "\n",
        "| Prediction | Actual | BCE Value | Interpretation |\n",
        "|------------|--------|-----------|----------------|\n",
        "| 0.99 | 1 | 0.01 | \"Not surprised at all - I expected this!\" |\n",
        "| 0.5 | 1 | 0.69 | \"Somewhat surprised - I was uncertain\" |\n",
        "| 0.01 | 1 | 4.61 | \"VERY surprised! I was confident it was NOT 1!\" |\n",
        "\n",
        "### The Mathematics\n",
        "\n",
        "$$\\text{BCE} = -\\frac{1}{n}\\sum_{i=1}^{n} \\left[ y_i \\cdot \\log(\\hat{y}_i) + (1-y_i) \\cdot \\log(1-\\hat{y}_i) \\right]$$\n",
        "\n",
        "This looks scary! Let's break it down:\n",
        "\n",
        "**When the actual label y = 1 (it IS vertical):**\n",
        "- The formula simplifies to: $-\\log(\\hat{y})$\n",
        "- If we predicted high (ŷ = 0.9): $-\\log(0.9) = 0.105$ (low loss - good!)\n",
        "- If we predicted low (ŷ = 0.1): $-\\log(0.1) = 2.303$ (high loss - bad!)\n",
        "\n",
        "**When the actual label y = 0 (it is NOT vertical):**\n",
        "- The formula simplifies to: $-\\log(1 - \\hat{y})$\n",
        "- If we predicted low (ŷ = 0.1): $-\\log(0.9) = 0.105$ (low loss - good!)\n",
        "- If we predicted high (ŷ = 0.9): $-\\log(0.1) = 2.303$ (high loss - bad!)\n",
        "\n",
        "### Committee Analogy\n",
        "\n",
        "*\"BCE measures how embarrassed the committee member should be. If they confidently voted 'definitely vertical!' (0.99) and it turned out to be horizontal, they should be VERY embarrassed. The logarithm captures this severe penalty for confident wrong answers.\"*\n",
        "\n",
        "### Let's Implement and Compare:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# =============================================================================\n",
        "# BINARY CROSS-ENTROPY: Step by Step\n",
        "# =============================================================================\n",
        "\n",
        "print(\"=\"*70)\n",
        "print(\"BINARY CROSS-ENTROPY (BCE): Step by Step\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# First, let's understand the log function\n",
        "print(\"\\n\" + \"-\"*70)\n",
        "print(\"UNDERSTANDING THE LOGARITHM\")\n",
        "print(\"-\"*70)\n",
        "print(\"\"\"\n",
        "The natural log (ln or log) has a special property:\n",
        "  - log(1) = 0        (no surprise when probability matches reality)\n",
        "  - log(0.5) = -0.69  (some surprise)\n",
        "  - log(0.1) = -2.30  (very surprised!)\n",
        "  - log(0.01) = -4.61 (extremely surprised!)\n",
        "\n",
        "As the probability gets closer to 0, log goes to -infinity.\n",
        "That's why BCE severely punishes confident wrong predictions!\n",
        "\"\"\")\n",
        "\n",
        "# Show the log curve\n",
        "print(\"  Let's calculate -log(ŷ) for different predictions:\")\n",
        "predictions = [0.99, 0.9, 0.7, 0.5, 0.3, 0.1, 0.01]\n",
        "print(f\"\\n  {'Prediction (ŷ)':<18} {'-log(ŷ)':<15} {'Interpretation'}\")\n",
        "print(\"  \" + \"-\"*60)\n",
        "for p in predictions:\n",
        "    neg_log = -np.log(p)\n",
        "    if neg_log < 0.5:\n",
        "        interp = \"Low loss (good prediction)\"\n",
        "    elif neg_log < 1.5:\n",
        "        interp = \"Medium loss\"\n",
        "    else:\n",
        "        interp = \"High loss (bad prediction!)\"\n",
        "    print(f\"  {p:<18} {neg_log:<15.4f} {interp}\")\n",
        "\n",
        "print(\"\\n\" + \"-\"*70)\n",
        "print(\"BCE CALCULATION FOR A SINGLE SAMPLE\")\n",
        "print(\"-\"*70)\n",
        "\n",
        "# Example 1: Actual is 1, prediction is 0.9 (good prediction)\n",
        "y_true_1 = 1\n",
        "y_pred_1 = 0.9\n",
        "\n",
        "print(f\"\\n  Example 1: Actual y = {y_true_1}, Predicted ŷ = {y_pred_1}\")\n",
        "print(f\"  (This is a GOOD prediction for a vertical line)\")\n",
        "print(f\"\\n  BCE formula: -[y * log(ŷ) + (1-y) * log(1-ŷ)]\")\n",
        "print(f\"\\n  Since y = 1, the (1-y) term becomes 0, so:\")\n",
        "print(f\"  BCE = -[{y_true_1} * log({y_pred_1}) + 0]\")\n",
        "print(f\"  BCE = -log({y_pred_1})\")\n",
        "print(f\"  BCE = -{np.log(y_pred_1):.4f}\")\n",
        "bce_1 = -np.log(y_pred_1)\n",
        "print(f\"  BCE = {bce_1:.4f}\")\n",
        "\n",
        "# Example 2: Actual is 1, prediction is 0.1 (bad prediction)\n",
        "y_true_2 = 1\n",
        "y_pred_2 = 0.1\n",
        "\n",
        "print(f\"\\n  Example 2: Actual y = {y_true_2}, Predicted ŷ = {y_pred_2}\")\n",
        "print(f\"  (This is a BAD prediction for a vertical line)\")\n",
        "print(f\"\\n  Since y = 1:\")\n",
        "print(f\"  BCE = -log({y_pred_2})\")\n",
        "print(f\"  BCE = -{np.log(y_pred_2):.4f}\")\n",
        "bce_2 = -np.log(y_pred_2)\n",
        "print(f\"  BCE = {bce_2:.4f}\")\n",
        "\n",
        "print(f\"\\n  Notice: The bad prediction has {bce_2/bce_1:.1f}x higher loss!\")\n",
        "\n",
        "# The BCE function\n",
        "print(\"\\n\" + \"-\"*70)\n",
        "print(\"THE BCE FUNCTION (for reuse)\")\n",
        "print(\"-\"*70)\n",
        "\n",
        "def binary_cross_entropy(y_true, y_pred):\n",
        "    \"\"\"\n",
        "    Binary Cross-Entropy loss function.\n",
        "    \n",
        "    Formula: BCE = -(1/n) * Σ[y*log(ŷ) + (1-y)*log(1-ŷ)]\n",
        "    \n",
        "    Parameters:\n",
        "        y_true: Array of actual labels (0 or 1)\n",
        "        y_pred: Array of predicted probabilities (0 to 1)\n",
        "    \n",
        "    Returns:\n",
        "        Single value representing average cross-entropy loss\n",
        "    \"\"\"\n",
        "    # Clip predictions to avoid log(0) which is undefined\n",
        "    epsilon = 1e-15  # A tiny number\n",
        "    y_pred = np.clip(y_pred, epsilon, 1 - epsilon)\n",
        "    \n",
        "    # Calculate BCE\n",
        "    bce = -np.mean(y_true * np.log(y_pred) + (1 - y_true) * np.log(1 - y_pred))\n",
        "    return bce\n",
        "\n",
        "print(\"\"\"\n",
        "def binary_cross_entropy(y_true, y_pred):\n",
        "    # Clip to avoid log(0) - would be undefined!\n",
        "    epsilon = 1e-15\n",
        "    y_pred = np.clip(y_pred, epsilon, 1 - epsilon)\n",
        "    \n",
        "    # BCE formula\n",
        "    return -np.mean(y_true * np.log(y_pred) + \n",
        "                    (1 - y_true) * np.log(1 - y_pred))\n",
        "\"\"\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# =============================================================================\n",
        "# VISUALIZE: MSE vs BCE\n",
        "# =============================================================================\n",
        "\n",
        "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
        "\n",
        "# Generate prediction values from 0.01 to 0.99\n",
        "y_pred_range = np.linspace(0.01, 0.99, 100)\n",
        "\n",
        "# When actual label is 1 (vertical line)\n",
        "mse_when_y_is_1 = (1 - y_pred_range) ** 2\n",
        "bce_when_y_is_1 = -np.log(y_pred_range)\n",
        "\n",
        "# Plot for y = 1\n",
        "ax1 = axes[0]\n",
        "ax1.plot(y_pred_range, mse_when_y_is_1, 'b-', linewidth=2, label='MSE')\n",
        "ax1.plot(y_pred_range, bce_when_y_is_1, 'r-', linewidth=2, label='BCE')\n",
        "ax1.set_xlabel('Prediction (ŷ)', fontsize=12)\n",
        "ax1.set_ylabel('Loss', fontsize=12)\n",
        "ax1.set_title('When Actual y = 1 (Vertical Line)\\nLower prediction = Higher loss', fontsize=12, fontweight='bold')\n",
        "ax1.legend()\n",
        "ax1.grid(True, alpha=0.3)\n",
        "ax1.set_xlim(0, 1)\n",
        "ax1.set_ylim(0, 5)\n",
        "ax1.axvline(x=0.5, color='gray', linestyle=':', alpha=0.5)\n",
        "ax1.annotate('If we predict 0.1\\nBCE = 2.3 (harsh!)\\nMSE = 0.81', \n",
        "             xy=(0.1, 2.3), xytext=(0.3, 3.5),\n",
        "             fontsize=9, arrowprops=dict(arrowstyle='->', color='red'))\n",
        "\n",
        "# When actual label is 0 (horizontal line)\n",
        "mse_when_y_is_0 = y_pred_range ** 2\n",
        "bce_when_y_is_0 = -np.log(1 - y_pred_range)\n",
        "\n",
        "# Plot for y = 0\n",
        "ax2 = axes[1]\n",
        "ax2.plot(y_pred_range, mse_when_y_is_0, 'b-', linewidth=2, label='MSE')\n",
        "ax2.plot(y_pred_range, bce_when_y_is_0, 'r-', linewidth=2, label='BCE')\n",
        "ax2.set_xlabel('Prediction (ŷ)', fontsize=12)\n",
        "ax2.set_ylabel('Loss', fontsize=12)\n",
        "ax2.set_title('When Actual y = 0 (Horizontal Line)\\nHigher prediction = Higher loss', fontsize=12, fontweight='bold')\n",
        "ax2.legend()\n",
        "ax2.grid(True, alpha=0.3)\n",
        "ax2.set_xlim(0, 1)\n",
        "ax2.set_ylim(0, 5)\n",
        "ax2.axvline(x=0.5, color='gray', linestyle=':', alpha=0.5)\n",
        "ax2.annotate('If we predict 0.9\\nBCE = 2.3 (harsh!)\\nMSE = 0.81', \n",
        "             xy=(0.9, 2.3), xytext=(0.5, 3.5),\n",
        "             fontsize=9, arrowprops=dict(arrowstyle='->', color='red'))\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"\\nKEY INSIGHT: BCE vs MSE\")\n",
        "print(\"=\"*60)\n",
        "print(\"\"\"\n",
        "Notice how BCE (red line) rises much more steeply than MSE (blue line)\n",
        "as predictions get worse?\n",
        "\n",
        "This is why BCE is preferred for classification:\n",
        "  - It SEVERELY punishes confident wrong predictions\n",
        "  - A prediction of 0.1 when the answer is 1 has BCE loss of 2.3\n",
        "  - The same prediction has MSE loss of only 0.81\n",
        "\n",
        "BCE creates stronger learning signals when the model is very wrong,\n",
        "which helps it learn faster and more reliably!\n",
        "\"\"\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## 5.4 Gradient Descent: Finding Better Weights\n",
        "\n",
        "Now we know HOW WRONG we are (the loss). But how do we make our predictions BETTER?\n",
        "\n",
        "This is where **optimization** comes in - the process of finding the best values for our weights.\n",
        "\n",
        "### The Optimization Problem\n",
        "\n",
        "Our Perceptron has 9 weights + 1 bias = **10 numbers** to choose. Each combination of these 10 numbers gives different predictions and a different loss.\n",
        "\n",
        "**The Question:** Out of the infinite possible combinations, which gives the LOWEST loss?\n",
        "\n",
        "**The Naive Approach:** Try all combinations! \n",
        "- But with continuous numbers, there are infinitely many combinations\n",
        "- Even with just 100 values per parameter: 100^10 = 10^20 combinations\n",
        "- That's more than the number of grains of sand on Earth!\n",
        "\n",
        "**The Smart Approach:** Use mathematics to **guide our search** toward better values.\n",
        "\n",
        "### What is a Derivative? (A Quick Refresher)\n",
        "\n",
        "The **derivative** tells you how much one quantity changes when you change another.\n",
        "\n",
        "**Simple Example:** You're driving a car.\n",
        "- Position = where you are\n",
        "- Derivative of position = **speed** (how fast position changes)\n",
        "- Derivative of speed = **acceleration** (how fast speed changes)\n",
        "\n",
        "**For Our Loss Function:**\n",
        "- Loss = how wrong we are\n",
        "- Derivative of loss w.r.t. weight = how much loss changes when we change the weight\n",
        "\n",
        "If the derivative is:\n",
        "- **Positive:** Increasing the weight increases loss → we should DECREASE the weight\n",
        "- **Negative:** Increasing the weight decreases loss → we should INCREASE the weight\n",
        "- **Zero:** We're at a minimum (or maximum)!\n",
        "\n",
        "### The Key Idea: The Loss Landscape\n",
        "\n",
        "Imagine the loss as a **landscape** where:\n",
        "- The **height** at any point = how wrong we are (higher = worse)\n",
        "- The **position** = our current weights\n",
        "- Our **goal** = find the lowest point (minimum loss)\n",
        "\n",
        "We want to \"roll downhill\" until we find the bottom!\n",
        "\n",
        "### The Algorithm: Gradient Descent\n",
        "\n",
        "**Gradient** means \"slope\" - it tells us which way is uphill.\n",
        "\n",
        "**Gradient Descent** means:\n",
        "1. Look at the slope where we are\n",
        "2. Take a step in the **opposite direction** (downhill)\n",
        "3. Repeat until we reach the bottom\n",
        "\n",
        "### The Mathematics\n",
        "\n",
        "$$w_{new} = w_{old} - \\alpha \\cdot \\frac{\\partial L}{\\partial w}$$\n",
        "\n",
        "Let's break this down:\n",
        "\n",
        "| Symbol | Meaning | Intuition |\n",
        "|--------|---------|-----------|\n",
        "| $w_{new}$ | Updated weight | Where we're going |\n",
        "| $w_{old}$ | Current weight | Where we are |\n",
        "| $\\alpha$ | Learning rate | How big a step to take |\n",
        "| $\\frac{\\partial L}{\\partial w}$ | Gradient (slope) | Which way is uphill |\n",
        "| $-$ | Subtraction | We go OPPOSITE to uphill (= downhill) |\n",
        "\n",
        "### Committee Analogy\n",
        "\n",
        "*\"The gradient is like a compass that always points uphill. We want to go DOWNHILL (less error), so we walk in the opposite direction. The learning rate decides whether we take small careful steps or big bold leaps.\"*\n",
        "\n",
        "### Let's Visualize This:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# =============================================================================\n",
        "# VISUALIZE: The Loss Landscape and Gradient Descent\n",
        "# =============================================================================\n",
        "\n",
        "# Create a simple 1D loss landscape (parabola)\n",
        "# This represents how loss changes as we change ONE weight\n",
        "weight_values = np.linspace(-3, 3, 100)\n",
        "loss_landscape = weight_values ** 2 + 0.5  # Simple parabola with minimum at w=0\n",
        "\n",
        "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
        "\n",
        "# Plot 1: The loss landscape\n",
        "ax1 = axes[0]\n",
        "ax1.plot(weight_values, loss_landscape, 'b-', linewidth=3)\n",
        "ax1.fill_between(weight_values, loss_landscape, alpha=0.2)\n",
        "ax1.set_xlabel('Weight Value (w)', fontsize=12)\n",
        "ax1.set_ylabel('Loss (L)', fontsize=12)\n",
        "ax1.set_title('The Loss Landscape\\n(For a Single Weight)', fontsize=12, fontweight='bold')\n",
        "ax1.grid(True, alpha=0.3)\n",
        "\n",
        "# Mark the minimum\n",
        "ax1.scatter([0], [0.5], color='green', s=200, zorder=5, marker='*', label='Minimum (goal)')\n",
        "ax1.annotate('Our goal: Find this minimum!', xy=(0, 0.5), xytext=(0.5, 2),\n",
        "            fontsize=10, arrowprops=dict(arrowstyle='->', color='green'))\n",
        "\n",
        "# Show current position\n",
        "current_w = 2.0\n",
        "current_loss = current_w ** 2 + 0.5\n",
        "ax1.scatter([current_w], [current_loss], color='red', s=150, zorder=5, label='Current position')\n",
        "ax1.axvline(x=current_w, color='red', linestyle='--', alpha=0.3)\n",
        "ax1.legend()\n",
        "\n",
        "# Plot 2: Gradient descent animation (multiple steps)\n",
        "ax2 = axes[1]\n",
        "ax2.plot(weight_values, loss_landscape, 'b-', linewidth=2, alpha=0.5)\n",
        "ax2.fill_between(weight_values, loss_landscape, alpha=0.1)\n",
        "ax2.set_xlabel('Weight Value (w)', fontsize=12)\n",
        "ax2.set_ylabel('Loss (L)', fontsize=12)\n",
        "ax2.set_title('Gradient Descent: Rolling Downhill\\n(Learning Rate α = 0.3)', fontsize=12, fontweight='bold')\n",
        "ax2.grid(True, alpha=0.3)\n",
        "\n",
        "# Simulate gradient descent\n",
        "learning_rate = 0.3\n",
        "w = 2.5  # Starting position\n",
        "path = [(w, w**2 + 0.5)]\n",
        "\n",
        "for step in range(8):\n",
        "    gradient = 2 * w  # Derivative of w² is 2w\n",
        "    w = w - learning_rate * gradient  # Gradient descent update\n",
        "    loss = w ** 2 + 0.5\n",
        "    path.append((w, loss))\n",
        "\n",
        "# Plot the path\n",
        "path = np.array(path)\n",
        "ax2.plot(path[:, 0], path[:, 1], 'ro-', markersize=8, linewidth=2, label='Gradient descent path')\n",
        "ax2.scatter([path[0, 0]], [path[0, 1]], color='red', s=200, zorder=5, marker='o', label='Start')\n",
        "ax2.scatter([path[-1, 0]], [path[-1, 1]], color='green', s=200, zorder=5, marker='*', label='End (near minimum)')\n",
        "\n",
        "# Add step numbers\n",
        "for i, (w_val, l_val) in enumerate(path):\n",
        "    ax2.annotate(f'{i}', xy=(w_val, l_val), xytext=(w_val+0.1, l_val+0.3),\n",
        "                fontsize=9, fontweight='bold')\n",
        "\n",
        "ax2.legend(loc='upper right')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"\\nGRADIENT DESCENT STEPS:\")\n",
        "print(\"=\"*60)\n",
        "print(f\"{'Step':<6} {'Weight (w)':<15} {'Gradient (2w)':<15} {'Update':<20} {'Loss'}\")\n",
        "print(\"-\"*60)\n",
        "w = 2.5\n",
        "for step in range(6):\n",
        "    gradient = 2 * w\n",
        "    update = -learning_rate * gradient\n",
        "    loss = w ** 2 + 0.5\n",
        "    print(f\"{step:<6} {w:<15.4f} {gradient:<15.4f} {update:<20.4f} {loss:.4f}\")\n",
        "    w = w + update  # Same as w = w - learning_rate * gradient\n",
        "\n",
        "print(\"-\"*60)\n",
        "print(f\"\\nStarted at w = 2.5 (loss = 6.75)\")\n",
        "print(f\"After 5 steps: w = {w:.4f} (loss = {w**2 + 0.5:.4f})\")\n",
        "print(f\"Getting closer to the minimum at w = 0 (loss = 0.5)!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## 5.5 Learning Rate: How Fast to Adjust\n",
        "\n",
        "The **learning rate** (α, alpha) controls how big each step is. It's one of the most important choices in training!\n",
        "\n",
        "### Parameters vs Hyperparameters\n",
        "\n",
        "Before we dive in, let's clarify an important distinction:\n",
        "\n",
        "| Term | What It Is | Examples | Who Sets It? |\n",
        "|------|------------|----------|--------------|\n",
        "| **Parameters** | Values the model LEARNS | Weights, Bias | The training algorithm |\n",
        "| **Hyperparameters** | Settings WE choose before training | Learning rate, number of epochs | The human (you!) |\n",
        "\n",
        "The learning rate is a **hyperparameter** - we choose it before training, and it affects HOW the model learns (but is not learned itself).\n",
        "\n",
        "### Why Learning Rate Matters So Much\n",
        "\n",
        "The learning rate multiplies the gradient to determine the step size:\n",
        "\n",
        "```\n",
        "step = learning_rate × gradient\n",
        "new_weight = old_weight - step\n",
        "```\n",
        "\n",
        "**The Problem:** Gradients can vary wildly:\n",
        "- Sometimes the gradient is 10.0 (steep slope)\n",
        "- Sometimes it's 0.001 (nearly flat)\n",
        "\n",
        "**The Learning Rate's Job:** Scale these gradients to reasonable step sizes.\n",
        "\n",
        "### The Goldilocks Problem\n",
        "\n",
        "| Learning Rate | Effect | Problem |\n",
        "|---------------|--------|---------|\n",
        "| **Too Large** (α = 1.0) | Big steps | Overshoot! Miss the minimum, bounce around |\n",
        "| **Too Small** (α = 0.001) | Tiny steps | Takes forever, might get stuck |\n",
        "| **Just Right** (α = 0.1) | Medium steps | Steady progress toward minimum |\n",
        "\n",
        "### The Mathematics\n",
        "\n",
        "Remember our update formula:\n",
        "\n",
        "$$w_{new} = w_{old} - \\alpha \\cdot \\text{gradient}$$\n",
        "\n",
        "- If gradient = 10 and α = 0.1: step size = 1.0 (reasonable)\n",
        "- If gradient = 10 and α = 1.0: step size = 10.0 (too big!)\n",
        "- If gradient = 10 and α = 0.001: step size = 0.01 (too small!)\n",
        "\n",
        "### Committee Analogy\n",
        "\n",
        "*\"The learning rate is how much the committee member adjusts after each mistake. Too much adjustment, and they overcorrect wildly. Too little, and they never improve. The right amount leads to steady learning.\"*\n",
        "\n",
        "### Let's See All Three Scenarios:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# =============================================================================\n",
        "# VISUALIZE: Learning Rate Effects\n",
        "# =============================================================================\n",
        "\n",
        "def run_gradient_descent(start_w, learning_rate, steps=15):\n",
        "    \"\"\"Run gradient descent and return the path.\"\"\"\n",
        "    w = start_w\n",
        "    path = [(w, w**2 + 0.5)]\n",
        "    for _ in range(steps):\n",
        "        gradient = 2 * w  # Derivative of w²\n",
        "        w = w - learning_rate * gradient\n",
        "        w = np.clip(w, -5, 5)  # Prevent explosion\n",
        "        loss = w ** 2 + 0.5\n",
        "        path.append((w, loss))\n",
        "    return np.array(path)\n",
        "\n",
        "fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
        "weight_values = np.linspace(-3, 3, 100)\n",
        "loss_landscape = weight_values ** 2 + 0.5\n",
        "\n",
        "scenarios = [\n",
        "    (0.9, 'TOO LARGE (α=0.9)', 'red', 'Overshoots and bounces!'),\n",
        "    (0.3, 'JUST RIGHT (α=0.3)', 'green', 'Steady progress!'),\n",
        "    (0.05, 'TOO SMALL (α=0.05)', 'blue', 'Very slow progress...')\n",
        "]\n",
        "\n",
        "for ax, (lr, title, color, desc) in zip(axes, scenarios):\n",
        "    ax.plot(weight_values, loss_landscape, 'k-', linewidth=1, alpha=0.3)\n",
        "    ax.fill_between(weight_values, loss_landscape, alpha=0.1, color='gray')\n",
        "    \n",
        "    path = run_gradient_descent(start_w=2.5, learning_rate=lr)\n",
        "    ax.plot(path[:, 0], path[:, 1], 'o-', color=color, markersize=6, linewidth=1.5)\n",
        "    ax.scatter([path[0, 0]], [path[0, 1]], color=color, s=150, zorder=5, marker='s', label='Start')\n",
        "    ax.scatter([path[-1, 0]], [path[-1, 1]], color='black', s=150, zorder=5, marker='*', label='End')\n",
        "    \n",
        "    ax.set_xlabel('Weight (w)', fontsize=11)\n",
        "    ax.set_ylabel('Loss', fontsize=11)\n",
        "    ax.set_title(f'{title}\\n{desc}', fontsize=11, fontweight='bold')\n",
        "    ax.set_xlim(-3, 3)\n",
        "    ax.set_ylim(0, 10)\n",
        "    ax.grid(True, alpha=0.3)\n",
        "    ax.legend(loc='upper right', fontsize=9)\n",
        "    \n",
        "    # Show final loss\n",
        "    ax.annotate(f'Final loss: {path[-1, 1]:.2f}', xy=(0, 8), fontsize=10, ha='center')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"\\nLEARNING RATE COMPARISON:\")\n",
        "print(\"=\"*60)\n",
        "for lr, title, _, _ in scenarios:\n",
        "    path = run_gradient_descent(start_w=2.5, learning_rate=lr)\n",
        "    print(f\"\\n{title}\")\n",
        "    print(f\"  Final weight: {path[-1, 0]:.4f}\")\n",
        "    print(f\"  Final loss:   {path[-1, 1]:.4f}\")\n",
        "    print(f\"  Optimal loss: 0.5000 (at w=0)\")\n",
        "    print(f\"  Distance from optimal: {abs(path[-1, 1] - 0.5):.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## 5.6 The Gradient: Which Way is Down?\n",
        "\n",
        "We've been using the word \"gradient\" - but what IS it exactly, and how do we calculate it?\n",
        "\n",
        "### What is a Gradient?\n",
        "\n",
        "The **gradient** is the **derivative** (slope) of the loss with respect to each weight. It tells us:\n",
        "- **How much** the loss changes when we change a weight\n",
        "- **Which direction** increases the loss (so we go the opposite way!)\n",
        "\n",
        "### Regular Derivatives vs Partial Derivatives\n",
        "\n",
        "**Regular derivative:** When you have ONE variable.\n",
        "- Example: If `f(x) = x²`, then `df/dx = 2x`\n",
        "\n",
        "**Partial derivative (∂):** When you have MULTIPLE variables and you want to see the effect of changing just ONE while keeping others fixed.\n",
        "- Example: If `f(x, y) = x² + y²`, then:\n",
        "  - `∂f/∂x = 2x` (how f changes when x changes, y held constant)\n",
        "  - `∂f/∂y = 2y` (how f changes when y changes, x held constant)\n",
        "\n",
        "**In our Perceptron:**\n",
        "- Loss depends on 9 weights + 1 bias = 10 variables\n",
        "- We need 10 partial derivatives (one for each parameter)\n",
        "- The **gradient** is the collection of ALL these partial derivatives\n",
        "\n",
        "### The Notation \"w.r.t.\" (With Respect To)\n",
        "\n",
        "You'll often see \"gradient of L w.r.t. w\" - this means \"how does L change when we change w?\"\n",
        "\n",
        "`∂L/∂w` is read as \"partial derivative of L with respect to w\"\n",
        "\n",
        "### The Chain Rule: Breaking Down Complex Functions\n",
        "\n",
        "Our Perceptron has multiple operations chained together:\n",
        "\n",
        "```\n",
        "x → [weighted sum] → z → [sigmoid] → ŷ → [BCE loss] → L\n",
        "    w · x + b                                \n",
        "```\n",
        "\n",
        "To find how changing **w** affects the final loss **L**, we use the **chain rule**:\n",
        "\n",
        "$$\\frac{\\partial L}{\\partial w} = \\frac{\\partial L}{\\partial \\hat{y}} \\cdot \\frac{\\partial \\hat{y}}{\\partial z} \\cdot \\frac{\\partial z}{\\partial w}$$\n",
        "\n",
        "This looks complicated, but each piece is simple!\n",
        "\n",
        "### The Beautiful Simplification\n",
        "\n",
        "For sigmoid activation with BCE loss, all the calculus simplifies to:\n",
        "\n",
        "$$\\frac{\\partial L}{\\partial w} = (\\hat{y} - y) \\cdot x$$\n",
        "\n",
        "And for the bias:\n",
        "\n",
        "$$\\frac{\\partial L}{\\partial b} = (\\hat{y} - y)$$\n",
        "\n",
        "That's it! The gradient is just:\n",
        "- **(prediction - actual)** × **input**\n",
        "\n",
        "### Why This Formula Makes Intuitive Sense\n",
        "\n",
        "| Part | Meaning | Intuition |\n",
        "|------|---------|-----------|\n",
        "| $(\\hat{y} - y)$ | Error | How wrong we are (and in which direction) |\n",
        "| $x$ | Input | Which inputs contributed to the output |\n",
        "\n",
        "If we predicted too high (ŷ > y), the error is positive, so we'll decrease the weights.\n",
        "If the input was large, we'll decrease more (because it had more influence).\n",
        "\n",
        "### Let's Calculate Gradients Step by Step:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# =============================================================================\n",
        "# CALCULATING GRADIENTS: Step by Step\n",
        "# =============================================================================\n",
        "\n",
        "print(\"=\"*70)\n",
        "print(\"CALCULATING GRADIENTS: Step by Step\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# Use our Perceptron on a vertical line\n",
        "x = vertical_flat.copy()\n",
        "y_true = 1  # It IS vertical\n",
        "\n",
        "# Get the prediction\n",
        "y_pred = perceptron.forward(x)\n",
        "\n",
        "print(f\"\\nInput (x): {x}\")\n",
        "print(f\"Actual label (y): {y_true}\")\n",
        "print(f\"Prediction (ŷ): {y_pred:.4f}\")\n",
        "\n",
        "# Calculate the error term\n",
        "print(\"\\n\" + \"-\"*70)\n",
        "print(\"STEP 1: Calculate the error term (ŷ - y)\")\n",
        "print(\"-\"*70)\n",
        "error = y_pred - y_true\n",
        "print(f\"\\n  error = ŷ - y\")\n",
        "print(f\"  error = {y_pred:.4f} - {y_true}\")\n",
        "print(f\"  error = {error:.4f}\")\n",
        "\n",
        "if error > 0:\n",
        "    print(f\"\\n  Interpretation: Error is POSITIVE ({error:.4f})\")\n",
        "    print(f\"  This means we predicted TOO HIGH - need to decrease output\")\n",
        "else:\n",
        "    print(f\"\\n  Interpretation: Error is NEGATIVE ({error:.4f})\")\n",
        "    print(f\"  This means we predicted TOO LOW - need to increase output\")\n",
        "\n",
        "# Calculate gradient for weights\n",
        "print(\"\\n\" + \"-\"*70)\n",
        "print(\"STEP 2: Calculate gradient for each weight\")\n",
        "print(\"-\"*70)\n",
        "print(f\"\\n  Formula: ∂L/∂w = (ŷ - y) × x = error × x\")\n",
        "print(f\"\\n  For each weight w_i, the gradient is: error × x_i\")\n",
        "\n",
        "gradient_weights = error * x\n",
        "print(f\"\\n  Gradients for all 9 weights:\")\n",
        "print(f\"  error × x = {error:.4f} × {x}\")\n",
        "print(f\"           = [{', '.join([f'{g:.4f}' for g in gradient_weights])}]\")\n",
        "\n",
        "# Show which weights should change\n",
        "print(f\"\\n  Let's interpret this (as a 3x3 grid):\")\n",
        "grad_grid = gradient_weights.reshape(3, 3)\n",
        "print(f\"    {grad_grid[0]}\")\n",
        "print(f\"    {grad_grid[1]}\")\n",
        "print(f\"    {grad_grid[2]}\")\n",
        "\n",
        "print(f\"\\n  Notice: Only the middle column has non-zero gradients!\")\n",
        "print(f\"  That's because only those pixels had value 1 in the input.\")\n",
        "print(f\"  Weights for other pixels don't need to change (input was 0).\")\n",
        "\n",
        "# Calculate gradient for bias\n",
        "print(\"\\n\" + \"-\"*70)\n",
        "print(\"STEP 3: Calculate gradient for bias\")\n",
        "print(\"-\"*70)\n",
        "gradient_bias = error\n",
        "print(f\"\\n  Formula: ∂L/∂b = (ŷ - y) = error\")\n",
        "print(f\"  Bias gradient = {gradient_bias:.4f}\")\n",
        "\n",
        "# Show the update\n",
        "print(\"\\n\" + \"-\"*70)\n",
        "print(\"STEP 4: Apply the update (with learning rate α = 0.5)\")\n",
        "print(\"-\"*70)\n",
        "learning_rate = 0.5\n",
        "print(f\"\\n  Update formula: w_new = w_old - α × gradient\")\n",
        "print(f\"\\n  For weight w₁ (position 1, middle column):\")\n",
        "old_w1 = perceptron.weights[1]\n",
        "new_w1 = old_w1 - learning_rate * gradient_weights[1]\n",
        "print(f\"    w₁_new = {old_w1:.4f} - {learning_rate} × {gradient_weights[1]:.4f}\")\n",
        "print(f\"    w₁_new = {old_w1:.4f} - {learning_rate * gradient_weights[1]:.4f}\")\n",
        "print(f\"    w₁_new = {new_w1:.4f}\")\n",
        "print(f\"\\n  Since error was negative, w₁ INCREASED to make output higher next time!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## 5.7 Backpropagation: Tracing the Blame\n",
        "\n",
        "**Backpropagation** (\"backprop\") is the algorithm that calculates gradients by flowing errors BACKWARD through the network.\n",
        "\n",
        "### Why Backpropagation is Revolutionary\n",
        "\n",
        "Before backpropagation was popularized in 1986 (by Rumelhart, Hinton, and Williams), training neural networks was incredibly difficult. People didn't know how to efficiently calculate gradients for networks with many layers.\n",
        "\n",
        "**The Problem:** In a network with multiple layers, changing one weight affects EVERYTHING that comes after it. How do you figure out exactly how much each weight contributed to the final error?\n",
        "\n",
        "**The Solution:** Backpropagation! It uses the chain rule to efficiently calculate ALL gradients in ONE backward pass through the network.\n",
        "\n",
        "### The Name Explained\n",
        "\n",
        "- **Back:** We start from the OUTPUT (the error) and work BACKWARD\n",
        "- **Propagation:** The error \"propagates\" (spreads) to earlier layers\n",
        "\n",
        "Think of it like blame assignment:\n",
        "1. The final output was wrong\n",
        "2. What caused it to be wrong? Trace backward...\n",
        "3. These specific weights were most responsible\n",
        "4. Adjust them accordingly\n",
        "\n",
        "### For Our Single Neuron\n",
        "\n",
        "In our simple Perceptron, backpropagation is straightforward:\n",
        "\n",
        "```\n",
        "    FORWARD PASS (left to right):\n",
        "    x → [w·x + b] → z → [sigmoid] → ŷ → [compare to y] → Loss\n",
        "    \n",
        "    BACKWARD PASS (right to left):\n",
        "    Loss → ∂L/∂ŷ → ∂L/∂z → ∂L/∂w, ∂L/∂b\n",
        "           ↑          ↑          ↑\n",
        "        \"How does   \"How does   \"How does\n",
        "         loss       loss        loss\n",
        "         change     change      change\n",
        "         with ŷ?\"   with z?\"    with w,b?\"\n",
        "```\n",
        "\n",
        "### Committee Analogy\n",
        "\n",
        "*\"Backpropagation is like a post-mortem after a mistake. The committee asks: 'What went wrong?' They trace the decision back: 'The final vote was wrong. Why? The weighted sum was off. Why? These specific weights gave too much importance to the wrong evidence.' Then they adjust those specific weights.\"*\n",
        "\n",
        "### The Backprop Flow for Our Perceptron\n",
        "\n",
        "| Step | Calculation | Formula |\n",
        "|------|-------------|---------|\n",
        "| 1 | Loss gradient w.r.t. output | $\\frac{\\partial L}{\\partial \\hat{y}}$ (from BCE) |\n",
        "| 2 | Output gradient w.r.t. pre-activation | $\\frac{\\partial \\hat{y}}{\\partial z} = \\hat{y}(1-\\hat{y})$ (sigmoid derivative) |\n",
        "| 3 | Pre-activation gradient w.r.t. weights | $\\frac{\\partial z}{\\partial w} = x$ |\n",
        "| 4 | Chain them together | $\\frac{\\partial L}{\\partial w} = (\\hat{y} - y) \\cdot x$ |\n",
        "\n",
        "The beautiful thing: steps 1 and 2 combine to give us just $(ŷ - y)$!\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## 5.8 The Training Loop: Putting It All Together\n",
        "\n",
        "Now we have all the pieces! Let's build the complete training algorithm.\n",
        "\n",
        "### Why Do We Need a Loop?\n",
        "\n",
        "A single gradient descent step makes only a TINY improvement. To go from random weights to good weights, we need MANY small steps.\n",
        "\n",
        "**Real Example:**\n",
        "- Start: Loss = 0.7, Accuracy = 50%\n",
        "- After 1 step: Loss = 0.69, Accuracy = 51%  (tiny improvement)\n",
        "- After 10 steps: Loss = 0.5, Accuracy = 65%\n",
        "- After 100 steps: Loss = 0.1, Accuracy = 95%\n",
        "\n",
        "Each step nudges the weights slightly. Over many steps, these tiny nudges accumulate into major improvements!\n",
        "\n",
        "### Why Multiple Epochs?\n",
        "\n",
        "**Problem:** One pass through the data isn't enough.\n",
        "- With 100 samples, we only make 100 weight updates\n",
        "- The model might not have \"seen\" enough patterns\n",
        "- Early samples were processed with very different weights than late samples\n",
        "\n",
        "**Solution:** Go through the data MULTIPLE times (epochs).\n",
        "- Epoch 1: First exposure to all samples\n",
        "- Epoch 2: Second look, with better weights now\n",
        "- Epoch 3: Refinement continues\n",
        "- ...\n",
        "\n",
        "Each epoch, the model gets better at the task!\n",
        "\n",
        "### The Training Loop Algorithm\n",
        "\n",
        "```\n",
        "FOR each epoch (pass through the data):\n",
        "    FOR each sample (x, y) in the training data:\n",
        "        \n",
        "        1. FORWARD PASS: Get prediction\n",
        "           ŷ = sigmoid(w · x + b)\n",
        "        \n",
        "        2. COMPUTE LOSS: How wrong?\n",
        "           L = BCE(y, ŷ)\n",
        "        \n",
        "        3. COMPUTE GRADIENTS: Which way to go?\n",
        "           ∂L/∂w = (ŷ - y) × x\n",
        "           ∂L/∂b = (ŷ - y)\n",
        "        \n",
        "        4. UPDATE WEIGHTS: Take a step downhill\n",
        "           w = w - α × ∂L/∂w\n",
        "           b = b - α × ∂L/∂b\n",
        "    \n",
        "    Record average loss for this epoch\n",
        "```\n",
        "\n",
        "### Key Terms\n",
        "\n",
        "| Term | Meaning |\n",
        "|------|---------|\n",
        "| **Epoch** | One complete pass through all training data |\n",
        "| **Sample** | One training example (input + label) |\n",
        "| **Batch** | Group of samples processed together (we use batch size = 1 here) |\n",
        "| **Iteration** | One weight update |\n",
        "\n",
        "### Let's Build Our Trainable Perceptron!\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# =============================================================================\n",
        "# THE TRAINABLE PERCEPTRON: Complete Implementation\n",
        "# =============================================================================\n",
        "\n",
        "class TrainablePerceptron:\n",
        "    \"\"\"\n",
        "    A Perceptron that can learn from examples!\n",
        "    \n",
        "    This class includes:\n",
        "    - Forward pass (prediction)\n",
        "    - Loss calculation (BCE)\n",
        "    - Gradient calculation (backpropagation)\n",
        "    - Weight update (gradient descent)\n",
        "    - Full training loop\n",
        "    \"\"\"\n",
        "    \n",
        "    def __init__(self, n_inputs):\n",
        "        \"\"\"Initialize with random weights.\"\"\"\n",
        "        self.weights = np.random.randn(n_inputs) * 0.1\n",
        "        self.bias = 0.0\n",
        "        self.n_inputs = n_inputs\n",
        "        \n",
        "        # For tracking training progress\n",
        "        self.loss_history = []\n",
        "        self.accuracy_history = []\n",
        "    \n",
        "    def forward(self, x):\n",
        "        \"\"\"Forward pass: compute prediction.\"\"\"\n",
        "        x = np.array(x).flatten()\n",
        "        z = np.dot(self.weights, x) + self.bias\n",
        "        return sigmoid(z)\n",
        "    \n",
        "    def predict(self, x):\n",
        "        \"\"\"Binary prediction (0 or 1).\"\"\"\n",
        "        return 1 if self.forward(x) >= 0.5 else 0\n",
        "    \n",
        "    def compute_loss(self, y_true, y_pred):\n",
        "        \"\"\"Compute BCE loss for one sample.\"\"\"\n",
        "        epsilon = 1e-15\n",
        "        y_pred = np.clip(y_pred, epsilon, 1 - epsilon)\n",
        "        return -(y_true * np.log(y_pred) + (1 - y_true) * np.log(1 - y_pred))\n",
        "    \n",
        "    def train(self, X, y, learning_rate=0.1, epochs=100, verbose=True):\n",
        "        \"\"\"\n",
        "        Train the Perceptron using gradient descent.\n",
        "        \n",
        "        Parameters:\n",
        "            X: Training inputs, shape (n_samples, n_features)\n",
        "            y: Training labels, shape (n_samples,)\n",
        "            learning_rate: Step size for gradient descent\n",
        "            epochs: Number of passes through the data\n",
        "            verbose: Whether to print progress\n",
        "        \n",
        "        Returns:\n",
        "            List of losses for each epoch\n",
        "        \"\"\"\n",
        "        self.loss_history = []\n",
        "        self.accuracy_history = []\n",
        "        \n",
        "        if verbose:\n",
        "            print(\"=\"*70)\n",
        "            print(\"TRAINING STARTED\")\n",
        "            print(\"=\"*70)\n",
        "            print(f\"  Samples: {len(X)}\")\n",
        "            print(f\"  Epochs: {epochs}\")\n",
        "            print(f\"  Learning rate: {learning_rate}\")\n",
        "            print()\n",
        "        \n",
        "        for epoch in range(epochs):\n",
        "            total_loss = 0\n",
        "            correct = 0\n",
        "            \n",
        "            # Go through each training sample\n",
        "            for i in range(len(X)):\n",
        "                xi = X[i]  # Input\n",
        "                yi = y[i]  # True label\n",
        "                \n",
        "                # ===== STEP 1: FORWARD PASS =====\n",
        "                y_pred = self.forward(xi)\n",
        "                \n",
        "                # ===== STEP 2: COMPUTE LOSS =====\n",
        "                loss = self.compute_loss(yi, y_pred)\n",
        "                total_loss += loss\n",
        "                \n",
        "                # Count correct predictions\n",
        "                if (y_pred >= 0.5 and yi == 1) or (y_pred < 0.5 and yi == 0):\n",
        "                    correct += 1\n",
        "                \n",
        "                # ===== STEP 3: COMPUTE GRADIENTS =====\n",
        "                # The beautiful simplification: gradient = (prediction - actual) * input\n",
        "                error = y_pred - yi\n",
        "                gradient_weights = error * xi\n",
        "                gradient_bias = error\n",
        "                \n",
        "                # ===== STEP 4: UPDATE WEIGHTS =====\n",
        "                self.weights = self.weights - learning_rate * gradient_weights\n",
        "                self.bias = self.bias - learning_rate * gradient_bias\n",
        "            \n",
        "            # Record progress\n",
        "            avg_loss = total_loss / len(X)\n",
        "            accuracy = correct / len(X)\n",
        "            self.loss_history.append(avg_loss)\n",
        "            self.accuracy_history.append(accuracy)\n",
        "            \n",
        "            # Print progress every 10 epochs\n",
        "            if verbose and (epoch + 1) % 10 == 0:\n",
        "                print(f\"  Epoch {epoch+1:3d}/{epochs}: Loss = {avg_loss:.4f}, Accuracy = {accuracy*100:.1f}%\")\n",
        "        \n",
        "        if verbose:\n",
        "            print()\n",
        "            print(\"=\"*70)\n",
        "            print(\"TRAINING COMPLETE!\")\n",
        "            print(\"=\"*70)\n",
        "            print(f\"  Final Loss: {self.loss_history[-1]:.4f}\")\n",
        "            print(f\"  Final Accuracy: {self.accuracy_history[-1]*100:.1f}%\")\n",
        "        \n",
        "        return self.loss_history\n",
        "\n",
        "print(\"TrainablePerceptron class created!\")\n",
        "print(\"Now let's train it and watch it learn...\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## 5.9 Watching It Learn!\n",
        "\n",
        "This is the moment we've been building toward. Let's train our Perceptron and watch it transform from a confused guesser into an expert line detector!\n",
        "\n",
        "### What to Watch For\n",
        "\n",
        "During training, you'll see:\n",
        "\n",
        "1. **Loss decreasing** - The model is making fewer/smaller mistakes\n",
        "2. **Accuracy increasing** - More predictions are correct\n",
        "3. **Eventually plateauing** - When the model has learned all it can\n",
        "\n",
        "### Convergence: When Has the Model Learned Enough?\n",
        "\n",
        "**Convergence** means the model has stopped improving significantly. Signs of convergence:\n",
        "\n",
        "| Sign | What It Looks Like | What It Means |\n",
        "|------|-------------------|---------------|\n",
        "| Loss plateaus | Loss curve flattens out | No more improvement possible |\n",
        "| Loss oscillates | Jumps up and down slightly | Near the minimum |\n",
        "| Accuracy stable | Stays at same level | Model has learned the pattern |\n",
        "\n",
        "**When to Stop Training:**\n",
        "- When loss stops decreasing for several epochs\n",
        "- When accuracy reaches acceptable level (e.g., 95%+)\n",
        "- When you've run out of patience!\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# =============================================================================\n",
        "# TRAINING THE PERCEPTRON: Watch It Learn!\n",
        "# =============================================================================\n",
        "\n",
        "# Create a fresh Perceptron\n",
        "np.random.seed(42)  # For reproducibility\n",
        "model = TrainablePerceptron(n_inputs=9)\n",
        "\n",
        "# Check initial performance (before training)\n",
        "print(\"BEFORE TRAINING:\")\n",
        "print(\"-\"*40)\n",
        "correct_before = sum(model.predict(X_train[i]) == y_train[i] for i in range(len(X_train)))\n",
        "print(f\"Accuracy: {correct_before}/{len(y_train)} = {correct_before/len(y_train)*100:.1f}%\")\n",
        "print(f\"(This is basically random guessing)\")\n",
        "print()\n",
        "\n",
        "# Train the model!\n",
        "losses = model.train(X_train, y_train, learning_rate=0.5, epochs=50)\n",
        "\n",
        "# Check final performance\n",
        "print(\"\\nAFTER TRAINING:\")\n",
        "print(\"-\"*40)\n",
        "correct_after = sum(model.predict(X_train[i]) == y_train[i] for i in range(len(X_train)))\n",
        "print(f\"Accuracy: {correct_after}/{len(y_train)} = {correct_after/len(y_train)*100:.1f}%\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# =============================================================================\n",
        "# VISUALIZE THE LEARNING PROGRESS\n",
        "# =============================================================================\n",
        "\n",
        "fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
        "\n",
        "# Plot 1: Loss over time\n",
        "ax1 = axes[0]\n",
        "ax1.plot(model.loss_history, 'b-', linewidth=2)\n",
        "ax1.set_xlabel('Epoch', fontsize=12)\n",
        "ax1.set_ylabel('Loss (BCE)', fontsize=12)\n",
        "ax1.set_title('Loss Decreasing Over Time', fontsize=12, fontweight='bold')\n",
        "ax1.grid(True, alpha=0.3)\n",
        "ax1.annotate(f'Start: {model.loss_history[0]:.2f}', xy=(0, model.loss_history[0]), \n",
        "            xytext=(5, model.loss_history[0]+0.1), fontsize=10)\n",
        "ax1.annotate(f'End: {model.loss_history[-1]:.2f}', xy=(len(model.loss_history)-1, model.loss_history[-1]), \n",
        "            xytext=(len(model.loss_history)-15, model.loss_history[-1]+0.1), fontsize=10)\n",
        "\n",
        "# Plot 2: Accuracy over time\n",
        "ax2 = axes[1]\n",
        "ax2.plot([a*100 for a in model.accuracy_history], 'g-', linewidth=2)\n",
        "ax2.set_xlabel('Epoch', fontsize=12)\n",
        "ax2.set_ylabel('Accuracy (%)', fontsize=12)\n",
        "ax2.set_title('Accuracy Increasing Over Time', fontsize=12, fontweight='bold')\n",
        "ax2.grid(True, alpha=0.3)\n",
        "ax2.set_ylim(0, 105)\n",
        "ax2.axhline(y=50, color='red', linestyle='--', alpha=0.5, label='Random guessing')\n",
        "ax2.legend()\n",
        "\n",
        "# Plot 3: Learned weights (as 3x3 grid)\n",
        "ax3 = axes[2]\n",
        "weights_grid = model.weights.reshape(3, 3)\n",
        "im = ax3.imshow(weights_grid, cmap='RdBu', vmin=-2, vmax=2)\n",
        "ax3.set_title('Learned Weights\\n(What the model looks for)', fontsize=12, fontweight='bold')\n",
        "for i in range(3):\n",
        "    for j in range(3):\n",
        "        ax3.text(j, i, f'{weights_grid[i,j]:.2f}', ha='center', va='center', fontsize=11, fontweight='bold')\n",
        "plt.colorbar(im, ax=ax3)\n",
        "ax3.set_xticks([])\n",
        "ax3.set_yticks([])\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"\\nKEY OBSERVATIONS:\")\n",
        "print(\"=\"*60)\n",
        "print(f\"1. Loss decreased from {model.loss_history[0]:.4f} to {model.loss_history[-1]:.4f}\")\n",
        "print(f\"2. Accuracy improved from ~50% to {model.accuracy_history[-1]*100:.1f}%\")\n",
        "print(f\"3. The learned weights show HIGH values in the middle column!\")\n",
        "print(f\"   This is exactly what we'd expect for a vertical line detector!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# =============================================================================\n",
        "# TEST ON CANONICAL EXAMPLES: Before vs After\n",
        "# =============================================================================\n",
        "\n",
        "print(\"=\"*70)\n",
        "print(\"TESTING ON CANONICAL EXAMPLES\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# Test on vertical line\n",
        "v_pred = model.forward(vertical_flat)\n",
        "print(f\"\\nVertical Line:\")\n",
        "print(f\"  Prediction: {v_pred:.4f} ({v_pred*100:.1f}% confident it's vertical)\")\n",
        "print(f\"  Actual: 1 (IS vertical)\")\n",
        "print(f\"  Result: {'CORRECT!' if v_pred >= 0.5 else 'Wrong'}\")\n",
        "\n",
        "# Test on horizontal line\n",
        "h_pred = model.forward(horizontal_flat)\n",
        "print(f\"\\nHorizontal Line:\")\n",
        "print(f\"  Prediction: {h_pred:.4f} ({h_pred*100:.1f}% confident it's vertical)\")\n",
        "print(f\"  Actual: 0 (NOT vertical)\")\n",
        "print(f\"  Result: {'CORRECT!' if h_pred < 0.5 else 'Wrong'}\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"THE PERCEPTRON HAS LEARNED!\")\n",
        "print(\"=\"*70)\n",
        "print(\"\"\"\n",
        "From random weights giving ~50% accuracy,\n",
        "our Perceptron now confidently classifies lines!\n",
        "\n",
        "It learned that:\n",
        "  - The MIDDLE COLUMN matters most for vertical lines\n",
        "  - Other pixels should have low/negative weights\n",
        "  \n",
        "This happened automatically through gradient descent -\n",
        "we never told it what a vertical line looks like!\n",
        "\"\"\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## Part 5 Summary: What We've Learned\n",
        "\n",
        "This was the most important notebook in the series! You've learned the core of how neural networks learn.\n",
        "\n",
        "### Key Concepts Mastered\n",
        "\n",
        "| Concept | Formula | Why It Matters |\n",
        "|---------|---------|----------------|\n",
        "| **Error** | y - ŷ | Measures how wrong we are |\n",
        "| **MSE Loss** | (1/n)Σ(y-ŷ)² | Penalizes errors, larger errors more |\n",
        "| **BCE Loss** | -[y·log(ŷ) + (1-y)·log(1-ŷ)] | Better for classification, harsh on confident mistakes |\n",
        "| **Gradient** | (ŷ - y) · x | Direction and magnitude of improvement |\n",
        "| **Gradient Descent** | w = w - α·∇L | Algorithm to find better weights |\n",
        "| **Learning Rate** | α | Controls step size (too big = overshoot, too small = slow) |\n",
        "| **Backpropagation** | Chain rule backward | Calculates gradients for all weights |\n",
        "\n",
        "### The Training Loop (Memorize This!)\n",
        "\n",
        "```python\n",
        "for epoch in range(epochs):\n",
        "    for x, y in training_data:\n",
        "        y_pred = forward(x)           # 1. Predict\n",
        "        loss = bce(y, y_pred)         # 2. Measure error\n",
        "        gradient = (y_pred - y) * x   # 3. Calculate gradient\n",
        "        weights -= lr * gradient      # 4. Update weights\n",
        "```\n",
        "\n",
        "### Committee Analogy Progress\n",
        "\n",
        "| Part | Committee Story |\n",
        "|------|-----------------|\n",
        "| Part 1-3 | Member learned procedures (math, weights, voting) |\n",
        "| Part 4 | First case - confused, random guessing |\n",
        "| **Part 5** | **Member receives feedback and LEARNS!** |\n",
        "| Part 6 | (Next) Evaluating the trained expert |\n",
        "\n",
        "### The Big Picture\n",
        "\n",
        "**Before Training:** Random weights → Random predictions → ~50% accuracy\n",
        "\n",
        "**After Training:** Learned weights → Meaningful predictions → ~95%+ accuracy\n",
        "\n",
        "The Perceptron discovered ON ITS OWN that vertical lines have pixels in the middle column!\n",
        "\n",
        "---\n",
        "\n",
        "## Knowledge Check\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "KNOWLEDGE CHECK - Part 5: Training\n",
            "============================================================\n",
            "\n",
            "Answer these questions to test your understanding:\n",
            "\n",
            "1. Why do we square errors in MSE?\n",
            "   A) To make the math easier\n",
            "   B) To prevent positive and negative errors from canceling out\n",
            "   C) To make errors smaller\n",
            "   D) Because computers prefer square numbers\n",
            "\n",
            "2. Why is BCE preferred over MSE for classification?\n",
            "   A) BCE is faster to compute\n",
            "   B) BCE uses less memory\n",
            "   C) BCE severely punishes confident wrong predictions\n",
            "   D) BCE always gives lower values\n",
            "\n",
            "3. What happens if the learning rate is too high?\n",
            "   A) Training is faster and better\n",
            "   B) The model overshoots the minimum and may never converge\n",
            "   C) The model learns more features\n",
            "   D) Nothing bad, higher is always better\n",
            "\n",
            "4. The gradient formula for our Perceptron is (ŷ - y) × x. What does the 'x' part mean?\n",
            "   A) Larger inputs get larger weight updates\n",
            "   B) The input is added to the gradient\n",
            "   C) X marks the spot\n",
            "   D) Nothing, it's just mathematical convention\n",
            "\n",
            "5. What is an 'epoch' in training?\n",
            "   A) One weight update\n",
            "   B) One forward pass\n",
            "   C) One complete pass through all training data\n",
            "   D) When the model reaches 100% accuracy\n",
            "\n",
            "\n",
            "============================================================\n",
            "Scroll down for answers...\n",
            "============================================================\n"
          ]
        }
      ],
      "source": [
        "# =============================================================================\n",
        "# KNOWLEDGE CHECK - Part 5\n",
        "# =============================================================================\n",
        "\n",
        "print(\"KNOWLEDGE CHECK - Part 5: Training\")\n",
        "print(\"=\"*60)\n",
        "print(\"\\nAnswer these questions to test your understanding:\\n\")\n",
        "\n",
        "questions = [\n",
        "    {\n",
        "        \"q\": \"1. Why do we square errors in MSE?\",\n",
        "        \"options\": [\n",
        "            \"A) To make the math easier\",\n",
        "            \"B) To prevent positive and negative errors from canceling out\",\n",
        "            \"C) To make errors smaller\",\n",
        "            \"D) Because computers prefer square numbers\"\n",
        "        ],\n",
        "        \"answer\": \"B\",\n",
        "        \"explanation\": \"Squaring makes all errors positive, so they add up rather than cancel. It also penalizes larger errors more.\"\n",
        "    },\n",
        "    {\n",
        "        \"q\": \"2. Why is BCE preferred over MSE for classification?\",\n",
        "        \"options\": [\n",
        "            \"A) BCE is faster to compute\",\n",
        "            \"B) BCE uses less memory\",\n",
        "            \"C) BCE severely punishes confident wrong predictions\",\n",
        "            \"D) BCE always gives lower values\"\n",
        "        ],\n",
        "        \"answer\": \"C\",\n",
        "        \"explanation\": \"BCE uses logarithms which give very large penalties when the model is confident but wrong (e.g., predicting 0.01 when answer is 1).\"\n",
        "    },\n",
        "    {\n",
        "        \"q\": \"3. What happens if the learning rate is too high?\",\n",
        "        \"options\": [\n",
        "            \"A) Training is faster and better\",\n",
        "            \"B) The model overshoots the minimum and may never converge\",\n",
        "            \"C) The model learns more features\",\n",
        "            \"D) Nothing bad, higher is always better\"\n",
        "        ],\n",
        "        \"answer\": \"B\",\n",
        "        \"explanation\": \"A high learning rate causes big jumps that overshoot the minimum, causing the loss to bounce around or even increase.\"\n",
        "    },\n",
        "    {\n",
        "        \"q\": \"4. The gradient formula for our Perceptron is (ŷ - y) × x. What does the 'x' part mean?\",\n",
        "        \"options\": [\n",
        "            \"A) Larger inputs get larger weight updates\",\n",
        "            \"B) The input is added to the gradient\",\n",
        "            \"C) X marks the spot\",\n",
        "            \"D) Nothing, it's just mathematical convention\"\n",
        "        ],\n",
        "        \"answer\": \"A\",\n",
        "        \"explanation\": \"The input 'x' determines which weights contributed to the output. Weights connected to larger inputs get larger updates because they had more influence.\"\n",
        "    },\n",
        "    {\n",
        "        \"q\": \"5. What is an 'epoch' in training?\",\n",
        "        \"options\": [\n",
        "            \"A) One weight update\",\n",
        "            \"B) One forward pass\",\n",
        "            \"C) One complete pass through all training data\",\n",
        "            \"D) When the model reaches 100% accuracy\"\n",
        "        ],\n",
        "        \"answer\": \"C\",\n",
        "        \"explanation\": \"An epoch is one complete pass through the entire training dataset. We typically train for many epochs until the model converges.\"\n",
        "    }\n",
        "]\n",
        "\n",
        "for q in questions:\n",
        "    print(q[\"q\"])\n",
        "    for opt in q[\"options\"]:\n",
        "        print(f\"   {opt}\")\n",
        "    print()\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"Scroll down for answers...\")\n",
        "print(\"=\"*60)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# =============================================================================\n",
        "# ANSWERS - Knowledge Check Part 5\n",
        "# =============================================================================\n",
        "\n",
        "print(\"ANSWERS - Part 5 Knowledge Check\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "for i, q in enumerate(questions, 1):\n",
        "    print(f\"\\n{i}. Answer: {q['answer']}\")\n",
        "    print(f\"   {q['explanation']}\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"How did you do?\")\n",
        "print(\"  5/5: Training Master!\")\n",
        "print(\"  4/5: Solid understanding!\")\n",
        "print(\"  3/5: Review the sections you missed\")\n",
        "print(\"  <3:  Re-read Part 5 - these concepts are crucial!\")\n",
        "print(\"=\"*60)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## What's Next?\n",
        "\n",
        "**Congratulations!** You've completed the most important notebook in this series!\n",
        "\n",
        "You now understand how neural networks **learn** - loss functions, gradient descent, and backpropagation are the foundation of ALL deep learning.\n",
        "\n",
        "### Coming Up in Part 6: Evaluation - The Trained Expert\n",
        "\n",
        "- **Training vs Inference** - Learning mode vs using mode\n",
        "- **Accuracy Metrics** - Precision, recall, F1 score\n",
        "- **Confusion Matrix** - Detailed prediction breakdown\n",
        "- **Interpretability** - What did the model actually learn?\n",
        "\n",
        "---\n",
        "\n",
        "**Continue to Part 6:** `part_6_evaluation.ipynb`\n",
        "\n",
        "---\n",
        "\n",
        "*\"The Perceptron has learned. Now it's time to see what it REALLY knows.\"*\n",
        "\n",
        "**The Brain's Decision Committee** - From Confusion to Competence\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
